{
    "models": [
      {
        "id": "llama3-8b",
        "model_name": "llama3:8b",
        "type": "ollama",
        "parameters": {
          "max_tokens": 2048,
          "temperature": 0.7
        }
      },
      {
        "id": "mistral-7b",
        "model_name": "mistral:7b",
        "type": "ollama",
        "parameters": {
          "max_tokens": 2048,
          "temperature": 0.7
        }
      },
      {
        "id": "phi3-3.8b",
        "model_name": "phi3:3.8b",
        "type": "ollama",
        "parameters": {
          "max_tokens": 2048,
          "temperature": 0.7
        }
      },
      {
        "id": "deepseek-r1-8b",
        "model_name": "deepseek-r1:8b",
        "type": "ollama",
        "parameters": {
          "max_tokens": 2048,
          "temperature": 0.7
        }
      }
    ],
    "output_dir": "results",
    "generate_visualizations": true,
    "generate_reports": true
  }