"""
LLM Benchmarking Framework

A package for benchmarking large language models by evaluating their performance
on various tasks including question answering, coding, reasoning, and agent-based scenarios.
"""

__version__ = "0.1.0"